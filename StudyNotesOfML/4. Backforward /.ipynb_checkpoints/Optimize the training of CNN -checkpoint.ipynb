{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to use gpu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mW1024 19:23:37 2009 minpy.dispatch.registry:register:47]\u001b[0m Type MXNet for name reshape has already existed\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import minpy.numpy\n",
    "import cupy\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Choose whether to use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np = numpy # Only use cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Determine the network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3340,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_units = 5 # the CNN ' size\n",
    "inrow, incol = 20, 20 # input size is (20, 20)\n",
    "krow, kcol = 5, 5 # the filtter size is (5, 5)\n",
    "crow, ccol = inrow - krow + 1, incol - kcol + 1 # the convolution result's size is (16, 16) \n",
    "pfrow, pfcol = 2, 2 # the pooling fillters' size is (2, 2)\n",
    "prow, pcol = crow // pfrow, ccol // pfcol # the pooling results' size is (8, 8) \n",
    "output_size = 10\n",
    "\n",
    "weights_size = (krow * kcol + 1 +# w and b of convolution layer\n",
    "                prow * pcol * output_size) * num_units + output_size # w of output layer\n",
    "params = (np.random.random(size=weights_size) - 0.5) * 0.25 # all weights\n",
    "params.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Initializate data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500, 20, 20), (3500, 10, 1), (1500, 20, 20), (1500, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat(\"ex4data1.mat\")\n",
    "X = data[\"X\"]\n",
    "m = X.shape[0]\n",
    "X = X.reshape((m, inrow, incol))\n",
    "y = data[\"y\"]\n",
    "\n",
    "training_set_scale = 0.7\n",
    "tr_m = int(m * training_set_scale)\n",
    "tr_X = np.array(X[:tr_m])\n",
    "ts_m = m - tr_m\n",
    "ts_X = np.array(X[tr_m:])\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories=\"auto\")\n",
    "y_onehot = onehot_encoder.fit_transform(y)\n",
    "tr_y = np.array(y_onehot[:tr_m]).reshape((tr_m, output_size, 1))\n",
    "ts_y = np.array(y[tr_m:])\n",
    "\n",
    "tr_X.shape, tr_y.shape, ts_X.shape, ts_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Initializate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3340,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = (np.random.random(size=weights_size) - 0.5) * 0.25\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Encode and decode weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(theta1, b1, theta2, b2):\n",
    "    return np.concatenate((theta1.ravel(), b1.ravel(), theta2.ravel(), b2.ravel()))\n",
    "def decode(weights, num_units, krow, kcol, prow, pcol, output_size):\n",
    "    theta1 = weights[:num_units*krow*kcol].reshape((num_units, krow, kcol))\n",
    "    b1 = weights[num_units*krow*kcol:num_units*krow*kcol+num_units].reshape((num_units, 1))\n",
    "    theta2 = weights[num_units*krow*kcol+num_units:\n",
    "                    -output_size].reshape((num_units, prow, pcol, output_size))\n",
    "    b2 = weights[-output_size:].reshape((output_size, 1))\n",
    "    return theta1, b1, theta2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 5, 5), (5, 1), (5, 8, 8, 10), (10, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1, b1, theta2, b2 = decode(weights, num_units, krow, kcol, prow, pcol, output_size)\n",
    "theta1.shape, b1.shape, theta2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3340,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(theta1, b1, theta2, b2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3340"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1.size + b1.size + theta2.size + b2.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convolution(X, w, krow, kcol, crow, ccol):\n",
    "    res = np.zeros((crow, ccol))\n",
    "    for i in range(crow):\n",
    "        for j in range(ccol):\n",
    "            temp = w * X[i:i+krow,j:j+kcol]\n",
    "    return res # (16, 16)\n",
    "a = convolution(tr_X[0], theta1[0], krow, kcol, crow, ccol)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPooling(conv, crow, ccol, pfrow, pfcol, prow, pcol):\n",
    "    res = np.zeros((prow, pcol))\n",
    "    grad = np.zeros((crow, ccol))\n",
    "    for i in range(0, crow, pfrow):\n",
    "        for j in range(0, ccol, pfrow):\n",
    "            res[i//2,j//2] = np.max(conv[i:i+pfrow,j:j+pcol])\n",
    "            idx = np.argmax(conv[i:i+pfrow,j:j+pcol])\n",
    "            grad[i+idx//pfrow,j+idx%pcol] = 1\n",
    "    return res, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Sigmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "sigmod = expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Forward propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPropagate(X, theta1, b1, theta2, b2, num_units, krow, kcol,\n",
    "                    crow, ccol, prow, pcol, output_size):\n",
    "    a1 = X # (20, 20)\n",
    "    z2 = np.zeros((num_units, crow, ccol)) # (5, 16, 16)\n",
    "    a2 = z2.copy() # (5, 16, 16)\n",
    "    pooling_grad = z2.copy() # (5, 16, 16)\n",
    "    a3 = np.zeros((num_units, prow, pcol)) # (5, 8, 8)\n",
    "    z4 = np.zeros((output_size, 1)) # (10, 1)\n",
    "    a4 = z4.copy() # (10, 1)\n",
    "    \n",
    "    for i in range(num_units):\n",
    "        z2[i] = convolution(X, theta1[i], krow, kcol, \n",
    "                            crow, ccol) + b1[i] # (16, 16)\n",
    "    a2 = sigmod(z2) # (5, 16, 16)\n",
    "    \n",
    "    for i in range(num_units):\n",
    "        a3[i], pooling_grad[i] = maxPooling(a2[i], crow, ccol, pfrow, pfcol, prow, pcol)\n",
    "    \n",
    "    for i in range(output_size):        \n",
    "         z4[i] += np.sum(theta2[:,:,:,i] * a3)\n",
    "    z4 += b2\n",
    "    a4 = sigmod(z4)\n",
    "    return a1, z2, a2, pooling_grad, a3, z4, a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 s, sys: 0 ns, total: 3.92 s\n",
      "Wall time: 3.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    a = forwardPropagate(X[0], theta1, b1, theta2, b2, num_units, krow, kcol,\n",
    "                    crow, ccol, prow, pcol, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta1, b1, theta2, b2, num_units, krow, kcol,\n",
    "                    crow, ccol, prow, pcol, output_size):\n",
    "    *t, h = forwardPropagate(X, theta1, b1, theta2, b2, num_units, krow, kcol,\n",
    "                    crow, ccol, prow, pcol, output_size)\n",
    "    return np.argmax(h) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 Comupte accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAccuracy(X, y, theta1, b1, theta2, b2, num_units, krow, kcol,\n",
    "                    crow, ccol, prow, pcol, output_size):\n",
    "    m = X.shape[0]\n",
    "    correct = 0\n",
    "    for i in range(m):\n",
    "        ans = predict(X[i], theta1, b1, theta2, b2, num_units, krow, kcol,\n",
    "                    crow, ccol, prow, pcol, output_size)\n",
    "        correct += ans == y[i]\n",
    "    return f\"m:{m} correct:{correct} accuracy:{100 * correct / m}%\"\n",
    "#computeAccuracy(X, y, theta1, b1, theta2, b2, num_units, krow, kcol,\n",
    "#                    crow, ccol, prow, pcol, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy in all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 s, sys: 7 ms, total: 19.5 s\n",
      "Wall time: 19.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'m:5000 correct:[500] accuracy:[10.]%'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "computeAccuracy(X, y, theta1, b1, theta2, b2, num_units, krow, kcol,\n",
    "                    crow, ccol, prow, pcol, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 Sigmod gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmodGradient(z):\n",
    "    t = expit(z)\n",
    "    return t * (1 - t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagate(weights,  X, num_units, krow, kcol,\n",
    "                    crow, ccol, pfrow, pfcol, prow, pcol, output_size, lam=0.):\n",
    "    m = X.shape[0]\n",
    "    theta1, b1, theta2, b2 = decode(weights, num_units, \n",
    "                                    krow, kcol, prow, pcol, output_size)\n",
    "    J = 0.\n",
    "    \n",
    "    theta1_grad = np.zeros(theta1.shape) # (5, 5, 5)\n",
    "    b1_grad = np.zeros(b1.shape) # (5, 1)\n",
    "    theta2_grad = np.zeros(theta2.shape) # (5, 8, 10, 10)\n",
    "    b2_grad = np.zeros(b2.shape) # (10, 1)\n",
    "    \n",
    "    for i in range(m):\n",
    "        a1, z2, a2, pooling_grad, a3, z4, a4 = forwardPropagate(X[i], \n",
    "                    theta1, b1, theta2, b2, num_units, krow, kcol,\n",
    "                    crow, ccol, prow, pcol, output_size)\n",
    "        J += -np.sum(y[i] * np.log(a4) + \n",
    "                    (1 - y[i]) * np.log(1 - a4)) # cost\n",
    "        dt2 = a4 - y[i] # (10, 1)\n",
    "        \n",
    "        b2_grad += dt2 # (10, 1)\n",
    "        \n",
    "        temp = dt2.reshape((1, 1, 1, output_size))\n",
    "        theta2_grad += a3.reshape((*a3.shape, 1)) * temp # (5, 8, 8, 10)\n",
    "        \n",
    "        temp2 = theta2 * temp # (5, 8, 8, 10)\n",
    "        temp3 = np.zeros((num_units, crow, ccol)) # (5, 16, 16)\n",
    "        \n",
    "        for j in range(num_units): #\n",
    "            for p in range(0, crow, pfrow):\n",
    "                for q in range(0, ccol, pfcol):\n",
    "                    val = np.sum(temp2[j,p//pfcol,q//pfcol])\n",
    "                    for p1 in range(pfrow):\n",
    "                        for q1 in range(pfcol):\n",
    "                            temp3[j,p+p1,q+q1] = val\n",
    "        \n",
    "\n",
    "        dt1 = temp3 * pooling_grad * a2 * (1 - a2) # (5, 16, 16)\n",
    "        \n",
    "        for j in range(num_units):\n",
    "            b1_grad[j] = np.sum(dt1[j])\n",
    "            for p in range(krow):\n",
    "                for q in range(kcol):\n",
    "                    theta1_grad[j,p,q] += np.sum(dt1[j] * a1[p:p+crow,q:q+ccol])\n",
    "    \n",
    "    J /= m\n",
    "    theta1_grad /= m\n",
    "    b1_grad /= m\n",
    "    theta2_grad /=m\n",
    "    b2_grad /= m\n",
    "    \n",
    "    #Regulation\n",
    "        \n",
    "    J += (float(lam) / (2 * m)) * (np.sum(theta1 ** 2) + np.sum(theta2 ** 2))\n",
    "    theta1_grad += theta1 * lam / m\n",
    "    theta2_grad += theta2 * lam / m\n",
    "    \n",
    "    return J, encode(theta1, b1, theta2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 ms, sys: 0 ns, total: 46.9 ms\n",
      "Wall time: 44.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "J, grad = backPropagate(weights,tr_X[:5], num_units, krow, kcol,\n",
    "                        crow, ccol, pfrow, pfcol, prow, pcol, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGradient(weights,  X,num_units, krow, kcol,\n",
    "                    crow, ccol, pfrow, pfcol, prow, pcol, output_size, lam=0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
